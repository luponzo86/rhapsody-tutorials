{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of EGFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle, csv, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert here local path to Rhapsody folder\n",
    "sys.path.insert(0, '../../rhapsody/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhapsody import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Dataset\n",
    "Let's import the training dataset. We will only consider variants in the Integrated Dataset with at least 1 ClinVar review star, if present, and an associated PDB structure larger than 150 residues, two restrictions that we found to improve prediction accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87726"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = np.load('../00-Training_Dataset/data/precomputed_features-ID.npy')\n",
    "\n",
    "ID = ID[ID['true_label'] != -1]\n",
    "len(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80215"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_SAVs_info = np.load('../00-Training_Dataset/data/Integrated_Dataset-SAVs.npy')\n",
    "zero_star_SAVs = ID_SAVs_info[ ID_SAVs_info['ClinVar_review_star'] == 0 ]['SAV_coords']\n",
    "\n",
    "ID = ID[ [SAV not in zero_star_SAVs for SAV in ID['SAV_coords']] ]\n",
    "len(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20361"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = ID[ID['PDB_length'] >= 150]\n",
    "len(ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-training of unbiased classifier\n",
    "\n",
    "A few EGFR mutations are found in the Integrated Dataset used for training. In order to get completely unbiased predictions, we will retrain a classifier by excluding those variants from the training dataset.\n",
    "\n",
    "**NB:** The Uniprot names for gene EGFR are `P00533` or `EGFR_HUMAN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 known deleterious EGFR SAVs:\n",
      "[('P00533 428 G D', 1, 'humsavar[1],clinvar[1]',  0)\n",
      " ('P00533 748 R T', 1, 'swissvar[1]', -1)\n",
      " ('P00533 787 Q R', 1, 'varibench[1]', -1)\n",
      " ('P00533 873 G E', 1, 'varibench[1]', -1)]\n",
      "\n",
      "12 known neutral EGFR SAVs:\n",
      "[('P00533 1034 L R', 0, 'humsavar[0],swissvar[0]', -1)\n",
      " ('P00533 1048 A V', 0, 'exovar[0]', -1)\n",
      " ('P00533 1210 A V', 0, 'humsavar[0],swissvar[0]', -1)\n",
      " ('P00533 266 P R', 0, 'humsavar[0],swissvar[0]', -1)\n",
      " ('P00533 521 R K', 0, 'humsavar[0],humvar[0],clinvar[0]',  2)\n",
      " ('P00533 674 V I', 0, 'humsavar[0],swissvar[0]', -1)\n",
      " ('P00533 769 V M', 0, 'humsavar[0],clinvar[0]',  0)\n",
      " ('P00533 833 L V', 0, 'humsavar[0],clinvar[0]',  0)\n",
      " ('P00533 838 L V', 0, 'humsavar[0],clinvar[0]',  0)\n",
      " ('P00533 962 R G', 0, 'humsavar[0]', -1)\n",
      " ('P00533 98 R Q', 0, 'humsavar[0]', -1)\n",
      " ('P00533 988 H P', 0, 'exovar[0],humsavar[0],humvar[0],clinvar[0]',  1)]\n"
     ]
    }
   ],
   "source": [
    "known_EGFR_SAVs = ID_SAVs_info[ [SAV.startswith('P00533') for SAV in ID_SAVs_info['SAV_coords']] ]\n",
    "\n",
    "known_del_SAVs = known_EGFR_SAVs[ known_EGFR_SAVs['true_label'] == 1 ]\n",
    "known_neu_SAVs = known_EGFR_SAVs[ known_EGFR_SAVs['true_label'] == 0 ]\n",
    "\n",
    "print(f'{len(known_del_SAVs)} known deleterious EGFR SAVs:')\n",
    "print(known_del_SAVs)\n",
    "print(f'\\n{len(known_neu_SAVs)} known neutral EGFR SAVs:')\n",
    "print(known_neu_SAVs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's exclude these variants from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20353"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_subset = ID[ [not SAV.startswith('P00533') for SAV in ID['SAV_coords']] ]\n",
    "len(ID_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this subset of the Integrated Dataset to train unbiased versions of Rhapsody classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "featsets = {\n",
    "    'full_clsf': [ 'wt_PSIC', 'Delta_PSIC', 'SASA', \n",
    "                   'ANM_MSF-chain', 'ANM_effectiveness-chain', 'ANM_sensitivity-chain',\n",
    "                   'stiffness-chain', 'entropy', 'ranked_MI', 'BLOSUM' ],\n",
    "    'redx_clsf': [ 'wt_PSIC', 'Delta_PSIC', 'SASA', \n",
    "                   'ANM_MSF-chain', 'ANM_effectiveness-chain', 'ANM_sensitivity-chain',\n",
    "                   'stiffness-chain', 'BLOSUM' ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers already trained.\n"
     ]
    }
   ],
   "source": [
    "from prody import LOGGER\n",
    "\n",
    "if os.path.isdir('results'):\n",
    "    print('Classifiers already trained.')\n",
    "else:\n",
    "    os.mkdir('results/')\n",
    "    \n",
    "    LOGGER.start('results/RF_training.log')\n",
    "    summaries = {}\n",
    "    \n",
    "    for clsf_version, featset in featsets.items():\n",
    "        folder = f'results/{clsf_version}'\n",
    "        os.mkdir(folder)\n",
    "        \n",
    "        f = ['SAV_coords', 'true_label'] + featset\n",
    "        output_dict = trainRFclassifier(ID_subset[f])\n",
    "        summaries[clsf_version] = output_dict['CV summary']\n",
    "        \n",
    "        for file in glob.glob('*png') + ['trained_classifier.pkl',]:\n",
    "            os.rename(file, os.path.join(folder, file))\n",
    "            \n",
    "        LOGGER.info('')\n",
    "                    \n",
    "    # store training summary into pickle\n",
    "    pickle.dump(summaries, open('results/summaries.pkl', 'wb'))\n",
    "\n",
    "    LOGGER.close('results/RF_training.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhapsody predictions\n",
    "We perform a complete scanning of all amino acid variants (*in silico* saturation mutagenesis).\n",
    "\n",
    "**NB:** PolyPhen-2 predictions are precomputed and saved in `data/pph2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions already precomputed\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('results/predictions'):\n",
    "    print('predictions already precomputed')\n",
    "    rh = pickle.load(open('results/predictions/rhapsody-pickle.pkl', 'rb'))\n",
    "else:\n",
    "    os.mkdir('results/predictions')\n",
    "    # run rhapsody\n",
    "    rh = rhapsody('data/pph2/pph2-full.txt', 'results/full_clsf/trained_classifier.pkl',\n",
    "                  aux_classifier='results/redx_clsf/trained_classifier.pkl', input_type='PP2')\n",
    "    # store files\n",
    "    for f in glob.glob('rhapsody-*.*'):\n",
    "        os.rename(f, os.path.join('results/predictions', f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of dimerization on predictions: the kinase domain\n",
    "We will compare predictions obatined by using a custom PDB structure with those obtained automatically by Rhapsody. \n",
    "In particular we will consider the *biological assembly* for the EGFR kinase domain, which is an asymmetric dimer that can be found in the PDB database. \n",
    "We will also consider different ways of including environmental effects (*reduced* vs *sliced* models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimer_pdb_file = 'data/2gs6-dimer.pdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions already precomputed\n",
      "predictions already precomputed\n",
      "predictions already precomputed\n"
     ]
    }
   ],
   "source": [
    "rh_dimer = {}\n",
    "\n",
    "for env_model in ['chain', 'reduced', 'sliced']:\n",
    "    folder = f'results/predictions_dimer-{env_model}'\n",
    "    if os.path.isdir(folder):\n",
    "        print('predictions already precomputed')\n",
    "        rh_dimer[env_model] = pickle.load(open(os.path.join(folder, 'rhapsody-pickle.pkl'), 'rb'))\n",
    "    else:\n",
    "        os.mkdir(folder)\n",
    "        # run rhapsody\n",
    "        _r = rhapsody('data/pph2/pph2-full.txt', 'results/full_clsf/trained_classifier.pkl',\n",
    "                      aux_classifier='results/redx_clsf/trained_classifier.pkl', input_type='PP2',\n",
    "                      custom_PDB=dimer_pdb_file, force_env=env_model)\n",
    "        rh_dimer[env_model] = _r\n",
    "        # store files\n",
    "        for f in glob.glob('rhapsody-*.*'):\n",
    "            os.rename(f, os.path.join(folder, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Rhapsody   chain    reduced   sliced\n",
      "Rhapsody    1.000     0.734     0.732     0.738     \n",
      "chain       0.734     1.000     0.986     0.935     \n",
      "reduced     0.732     0.986     1.000     0.932     \n",
      "sliced      0.738     0.935     0.932     1.000     \n"
     ]
    }
   ],
   "source": [
    "# correlation between predictions\n",
    "\n",
    "from scipy.stats.stats import spearmanr\n",
    "\n",
    "sel1 = ~np.isnan(rh_dimer['chain'].mixPreds['score'])\n",
    "sel2 = [x.startswith('3GOP') for x in rh.Uniprot2PDBmap['PDB SAV coords']]\n",
    "sel = np.logical_and(sel1, sel2)\n",
    "\n",
    "pred_sets = [('Rhapsody', rh), ('chain', rh_dimer['chain']), \n",
    "             ('reduced', rh_dimer['reduced']), ('sliced', rh_dimer['sliced'])]\n",
    "\n",
    "print(\" \"*11 + f\"Rhapsody   chain    reduced   sliced\")\n",
    "\n",
    "for (s_i, r_i) in pred_sets:\n",
    "    print(f'{s_i:12}', end='')\n",
    "    for (s_j, r_j) in pred_sets:\n",
    "        rho = spearmanr(r_i.mixPreds['score'][sel], r_j.mixPreds['score'][sel])\n",
    "        print(f'{rho[0]:5.3f}', end=' '*5)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAV                Rhapsody/chain/reduced/sliced   true_labels\n",
      "P00533 1034 L R      ?      ?      ?      ?        0  humsavar[0],swissvar[0]\n",
      "P00533 1048 A V      ?      ?      ?      ?        0  exovar[0]\n",
      "P00533 1210 A V      ?      ?      ?      ?        0  humsavar[0],swissvar[0]\n",
      "P00533 266 P R       neu    ?      ?      ?        0  humsavar[0],swissvar[0]\n",
      "P00533 428 G D       del    ?      ?      ?        1  humsavar[1],clinvar[1]\n",
      "P00533 521 R K       neu    ?      ?      ?        0  humsavar[0],humvar[0],clinvar[0]**\n",
      "P00533 674 V I       neu    ?      ?      ?        0  humsavar[0],swissvar[0]\n",
      "P00533 709 E A       del    neu    p.neu  p.neu   -1  humsavar[0],varibench[1],clinvar[0]*\n",
      "P00533 709 E G       del    del    del    del     -1  humsavar[0],swissvar[1],clinvar[0]*\n",
      "P00533 709 E K       del    neu    neu    neu     -1  humsavar[0],varibench[1],clinvar[0]\n",
      "P00533 719 G A       del    del    del    del     -1  humsavar[0],varibench[1],clinvar[1]*\n",
      "P00533 719 G C       del    del    del    del     -1  humsavar[0],swissvar[1],varibench[1],clinvar[1]\n",
      "P00533 719 G D       del    del    del    del     -1  humsavar[0],varibench[1]\n",
      "P00533 719 G S       del    del    del    del     -1  humsavar[0],clinvar[1]*\n",
      "P00533 724 G S       del    del    del    del     -1  humsavar[0],varibench[1]\n",
      "P00533 734 E K       del    neu    neu    neu     -1  humsavar[0],varibench[1]\n",
      "P00533 748 R T       neu    ?      ?      ?        1  swissvar[1]\n",
      "P00533 768 S I       del    del    del    del     -1  humsavar[0],clinvar[1]*\n",
      "P00533 769 V M       neu    neu    neu    neu      0  humsavar[0],clinvar[0]\n",
      "P00533 787 Q R       del    del    del    del      1  varibench[1]\n",
      "P00533 790 T M       del    del    del    del     -1  humsavar[0],varibench[1],clinvar[1]***\n",
      "P00533 833 L V       neu    neu    neu    neu      0  humsavar[0],clinvar[0]\n",
      "P00533 834 V L       del    p.neu  neu    del     -1  humsavar[0],clinvar[1]*\n",
      "P00533 835 H L       del    del    del    del     -1  humsavar[0],swissvar[1],clinvar[0]\n",
      "P00533 838 L V       del    del    del    del      0  humsavar[0],clinvar[0]\n",
      "P00533 858 L M       del    del    del    del     -1  humsavar[0],clinvar[1]*\n",
      "P00533 858 L R       del    del    del    del     -1  humsavar[0],clinvar[1]***\n",
      "P00533 861 L Q       del    del    del    del     -1  humsavar[0],varibench[1],clinvar[1]\n",
      "P00533 873 G E       neu    neu    neu    neu      1  varibench[1]\n",
      "P00533 962 R G       neu    neu    neu    neu      0  humsavar[0]\n",
      "P00533 98 R Q        neu    ?      ?      ?        0  humsavar[0]\n",
      "P00533 988 H P       neu    neu    neu    neu      0  exovar[0],humsavar[0],humvar[0],clinvar[0]*\n"
     ]
    }
   ],
   "source": [
    "# comparison with 'true_labels' found in the Integrated Dataset\n",
    "\n",
    "abbrv = {'?': '?', 'neutral': 'neu', 'prob.neutral': 'p.neu',\n",
    "         'deleterious': 'del', 'prob.deleterious': 'p.del'}\n",
    "\n",
    "print(f\"SAV                Rhapsody/chain/reduced/sliced   true_labels\")\n",
    "\n",
    "for SAV in known_EGFR_SAVs:\n",
    "    for i, s in enumerate(rh.SAVcoords['text']):\n",
    "        # Rhapsody predictions\n",
    "        preds = \"\"\n",
    "        if s == SAV['SAV_coords']:\n",
    "            for r in [rh, rh_dimer['chain'], rh_dimer['reduced'], rh_dimer['sliced']]:\n",
    "                p = r.mixPreds[i]['path. class']\n",
    "                preds += f\"{abbrv[p]:6} \" \n",
    "            if SAV['ClinVar_review_star'] != -1:\n",
    "                stars = \"*\" * SAV['ClinVar_review_star']\n",
    "            else:\n",
    "                stars = \"\"\n",
    "            print(f\"{SAV['SAV_coords']:20} {preds} {SAV['true_label']:2}  {SAV['datasets']}{stars}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we plot the average predictions on the PDB structures to highlight the differences between the various approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('figures'):\n",
    "    os.mkdir('figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> PDB file is found in the local folder (/home/lponzoni/.../3gop.pdb.gz).\n",
      "@> 2385 atoms and 1 coordinate set(s) were parsed in 0.03s.\n",
      "@> 9984 atoms and 1 coordinate set(s) were parsed in 0.10s.\n",
      "@> 9984 atoms and 1 coordinate set(s) were parsed in 0.09s.\n",
      "@> 9984 atoms and 1 coordinate set(s) were parsed in 0.08s.\n"
     ]
    }
   ],
   "source": [
    "from prody import *\n",
    "\n",
    "for case in ['Rhapsody', 'chain', 'reduced', 'sliced']:\n",
    "    if case == 'Rhapsody':\n",
    "        PDBID = '3GOP'\n",
    "        r = rh\n",
    "        pdb = parsePDB('3GOP')\n",
    "    else:\n",
    "        PDBID = '2gs6'\n",
    "        r = rh_dimer[case]\n",
    "        pdb = parsePDB(dimer_pdb_file)\n",
    "        \n",
    "    probs = {} \n",
    "    for U2PDBmap, pred in zip(r.Uniprot2PDBmap['PDB SAV coords'], \n",
    "                              r.mixPreds['path. probability']):\n",
    "        if not U2PDBmap.startswith(PDBID):\n",
    "            continue\n",
    "        res = int(U2PDBmap.split()[2])\n",
    "        probs.setdefault(res, [])\n",
    "        probs[res].append(pred)\n",
    "\n",
    "    PDBresids = pdb.getResnums()\n",
    "    new_betas = np.zeros_like(PDBresids, dtype=float)\n",
    "    for i, res in enumerate(PDBresids):\n",
    "        if res in probs:\n",
    "            x = np.nanmean(probs[res])\n",
    "            beta = -1 if np.isnan(x) else x\n",
    "        else:\n",
    "            beta = -1\n",
    "        new_betas[i] = beta\n",
    "    # write modified PDB\n",
    "    pdb.setBetas(new_betas)\n",
    "    f = writePDB(f'figures/{case}-mapped', pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
