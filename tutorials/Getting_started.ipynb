{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Rhapsody\n",
    "\n",
    "## Installation\n",
    "Follow instructions in the git repository [README file](https://github.com/luponzo86/rhapsody/blob/master/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rhapsody as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lponzoni/Downloads/temporary_folder_for_Rhapsody'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.pathRhapsodyFolder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lponzoni/Data/025-EVmutation/mutation_effects'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.pathEVmutationFolder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of default classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tarfile, glob, pickle\n",
    "import numpy as np\n",
    "import prody as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('local'):\n",
    "    os.mkdir('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data\n",
    "tar = tarfile.open('../paper_Supplementary_Info/00-Training_Dataset/data.tar.gz', \"r:gz\")\n",
    "tar.extractall(path='local')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import precomputed features\n",
    "ID = np.load('local/data/precomputed_features-ID_opt.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featsets = {\n",
    "    'v2': [        # full classifier\n",
    "        'wt_PSIC', 'Delta_PSIC', 'SASA', \n",
    "        'ANM_MSF-chain', 'ANM_effectiveness-chain', 'ANM_sensitivity-chain',\n",
    "        'stiffness-chain', 'entropy', 'ranked_MI', 'BLOSUM'\n",
    "    ],\n",
    "    'v2_noPfam': [ # reduced classifier\n",
    "        'wt_PSIC', 'Delta_PSIC', 'SASA', \n",
    "        'ANM_MSF-chain', 'ANM_effectiveness-chain', 'ANM_sensitivity-chain',\n",
    "        'stiffness-chain', 'BLOSUM'\n",
    "    ],\n",
    "    'v2_EVmut': [  # full classifier + EVmutation epistatic score\n",
    "        'wt_PSIC', 'Delta_PSIC', 'SASA', \n",
    "        'ANM_MSF-chain', 'ANM_effectiveness-chain', 'ANM_sensitivity-chain',\n",
    "        'stiffness-chain', 'entropy', 'ranked_MI', 'BLOSUM', 'EVmut-DeltaE_epist'\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('local/results'):\n",
    "    os.mkdir('local/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pickle containing precomputed results has been found.\n",
      "Please delete it if you wish to run the training procedure again.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('local/results/RF_training_summaries.pkl'):\n",
    "    print('A pickle containing precomputed results has been found.')\n",
    "    print('Please delete it if you wish to run the training procedure again.')\n",
    "else:\n",
    "    pd.LOGGER.start('local/results/RF_training.log')\n",
    "    RF_training_summaries = {}\n",
    "\n",
    "    for version in ['v2', 'v2_noPfam', 'v2_EVmut']:\n",
    "        \n",
    "        featset = ['SAV_coords', 'true_label'] + featsets[version]\n",
    "\n",
    "        pd.LOGGER.info(f'VERSION: {version}')\n",
    "\n",
    "        # create folder\n",
    "        folder = f'local/results/RF_training-{version}'\n",
    "        os.mkdir(folder)\n",
    "\n",
    "        # run training procedure\n",
    "        output_dict = rd.trainRFclassifier(ID[featset])\n",
    "        RF_training_summaries[version] = output_dict['CV summary']\n",
    "\n",
    "        # move trained classifier and figures into folder\n",
    "        for file in glob.glob('*png') + ['trained_classifier.pkl',]:\n",
    "            os.rename(file, os.path.join(folder, file))\n",
    "\n",
    "        pd.LOGGER.info('')\n",
    "                    \n",
    "    # store all cross-validation results into a pickle\n",
    "    pickle.dump(RF_training_summaries, open('local/results/RF_training_summaries.pkl', 'wb'))\n",
    "\n",
    "    pd.LOGGER.close('local/results/RF_training.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('local/results/predictions'):\n",
    "    os.mkdir('local/results/predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> Logging into file: rhapsody-log.txt\n",
      "@> Logging started at 2019-06-13 13:58:04.520839\n",
      "@> Imported feature set: 'wt_PSIC'\n",
      "@>                       'Delta_PSIC'\n",
      "@>                       'SASA'\n",
      "@>                       'ANM_MSF-chain'\n",
      "@>                       'ANM_effectiveness-chain'\n",
      "@>                       'ANM_sensitivity-chain'\n",
      "@>                       'stiffness-chain'\n",
      "@>                       'entropy'\n",
      "@>                       'ranked_MI'\n",
      "@>                       'BLOSUM'\n",
      "@> Submitting query to PolyPhen-2...\n",
      "@> Query to PolyPhen-2 started in 12.8s.\n",
      "@> PolyPhen-2 is running...\n",
      "@> Query to PolyPhen-2 completed in 1.3s.\n",
      "@> PolyPhen-2's output parsed.\n",
      "@> Sequence-conservation features have been retrieved from PolyPhen-2's output.\n",
      "@> Mapping SAVs to PDB structures...\n",
      "@> [1/2] Mapping SAV 'O00238 31 R H' to PDB...\n",
      "@> Pickle 'UniprotMap-O00238.pkl' recovered.\n",
      "@> [2/2] Mapping SAV 'O00294 496 A T' to PDB...\n",
      "@> Pickle 'UniprotMap-O00238.pkl' saved.\n",
      "@> Pickle 'UniprotMap-O00294.pkl' recovered.\n",
      "@> Pickle 'UniprotMap-O00294.pkl' saved.\n",
      "@> SAVs have been mapped to PDB in 0.0s.\n",
      "@> Computing structural and dynamical features from PDB structures...\n",
      "@> [2/2] Analizing mutation site 2FIM:A 443...\n",
      "@> Pickle 'PDBfeatures-2FIM.pkl' recovered.\n",
      "@> Pickle 'PDBfeatures-2FIM.pkl' saved.\n",
      "@> PDB features have been computed in 0.0s.\n",
      "@> Computing sequence properties from Pfam domains...\n",
      "@> [1/2] Mapping SAV 'O00238 31 R H' to Pfam...\n",
      "@> Pickle 'UniprotMap-O00238.pkl' recovered.\n",
      "@> [2/2] Mapping SAV 'O00294 496 A T' to Pfam...\n",
      "@> Pickle 'UniprotMap-O00238.pkl' saved.\n",
      "@> Pickle 'UniprotMap-O00294.pkl' recovered.\n",
      "@> Pickle 'UniprotMap-O00294.pkl' saved.\n",
      "@> SAVs have been mapped on Pfam domains and sequence properties have been computed in 0.0s.\n",
      "@> Random Forest classifier imported in 0.4s.\n",
      "@> 1 predictions computed in 0.4s.\n",
      "@> Auxiliary Random Forest classifier imported.\n",
      "@> 1 predictions computed in 0.4s.\n",
      "@> Logging stopped at 2019-06-13 13:58:23.284429\n",
      "@> Closing logfile: rhapsody-log.txt\n"
     ]
    }
   ],
   "source": [
    "test_SAVs = ['O00294 496 A T', 'O00238 31 R H']\n",
    "\n",
    "os.chdir('local/results/predictions')\n",
    "\n",
    "rh = rd.rhapsody(test_SAVs, '../RF_training-v2/trained_classifier.pkl',\n",
    "                 aux_classifier='../RF_training-v2_noPfam/trained_classifier.pkl')\n",
    "\n",
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0.102, 0.05459946, 'neutral', 'known_neu'),\n",
       "       (  nan,        nan, '?', 'new')],\n",
       "      dtype=[('score', '<f4'), ('path. probability', '<f4'), ('path. class', '<U12'), ('training info', '<U12')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
