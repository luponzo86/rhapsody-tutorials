{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** There is no need to run this notebook, the relevant output is precomputed and saved to `imported_dbNSFP_predictions.tar.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# The following command will download about 25GB\n",
    "wget ftp://dbnsfp:dbnsfp@dbnsfp.softgenetics.com/dbNSFP4.0a.zip\n",
    "gunzip dbNSFP4.0a.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert here the location of the folder containing the\n",
    "# uncompressed dbSNFP dataset. The folder should contain a list of\n",
    "# files named 'dbNSFP4.0a_variant.chr*.gz'\n",
    "dbNSFP_dir = 'path_to_downloaded_dbNSFP/'\n",
    "\n",
    "# Insert here the path to the Rhapsody dataset of\n",
    "# precomputed features called 'precomputed_features-ID.npy'\n",
    "ID = np.load('../../1-Training_Dataset/local/data/precomputed_features-ID.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns in dbNSFP containing functional predictions from\n",
    "# various tools and info about their interpretation (adapted from\n",
    "# dbNSFP4.0a.readme.txt). For instance, '+' means that a larger\n",
    "# score corresponds to damaging effect, '-' means that a smaller\n",
    "# score corresponds to damaging effect, 'DP/B' means that letters\n",
    "# 'D' and 'P' will be considered as 'deleterious' and 'B' as 'neutral'.\n",
    "dbNSFP_sel_columns = [\n",
    "    (37, 'SIFT_score', '-'),\n",
    "    (39, 'SIFT_pred', 'D/T'),\n",
    "    (40, 'SIFT4G_score', '-'),\n",
    "    (42, 'SIFT4G_pred', 'D/T'),\n",
    "    (43, 'Polyphen2_HDIV_score', '+'),\n",
    "    (45, 'Polyphen2_HDIV_pred', 'DP/B'),\n",
    "    (46, 'Polyphen2_HVAR_score', '+'),\n",
    "    (48, 'Polyphen2_HVAR_pred', 'DP/B'),\n",
    "    (49, 'LRT_score', '-'),\n",
    "    (51, 'LRT_pred', 'D/N'),\n",
    "    (53, 'MutationTaster_score', '+'),\n",
    "    (55, 'MutationTaster_pred', 'AD/NP'),\n",
    "    (58, 'MutationAssessor_score', '+'),\n",
    "    (60, 'MutationAssessor_pred', 'HM/LN'),\n",
    "    (61, 'FATHMM_score', '-'),\n",
    "    (63, 'FATHMM_pred', 'D/T'),\n",
    "    (64, 'PROVEAN_score', '-'),\n",
    "    (66, 'PROVEAN_pred', 'D/N'),\n",
    "    (67, 'VEST4_score', '+'),\n",
    "    (69, 'MetaSVM_score', '+'),\n",
    "    (71, 'MetaSVM_pred', 'D/T'),\n",
    "    (72, 'MetaLR_score', '+'),\n",
    "    (74, 'MetaLR_pred', 'D/T'),\n",
    "    (76, 'M-CAP_score', '+'),\n",
    "    (78, 'M-CAP_pred', 'D/T'),\n",
    "    (79, 'REVEL_score', '+'),\n",
    "    (81, 'MutPred_score', '+'),\n",
    "    (86, 'MVP_score', '+'),\n",
    "    (88, 'MPC_score', '+'),\n",
    "    (90, 'PrimateAI_score', '+'),\n",
    "    (92, 'PrimateAI_pred', 'D/T'),\n",
    "    (93, 'DEOGEN2_score', '+'),\n",
    "    (95, 'DEOGEN2_pred', 'D/T'),\n",
    "    (102, 'CADD_raw', '+'),\n",
    "    (105, 'DANN_score', '+'),\n",
    "    (107, 'fathmm-MKL_coding_score', '+'),\n",
    "    (109, 'fathmm-MKL_coding_pred', 'D/N'),\n",
    "    (111, 'fathmm-XF_coding_score', '+'),\n",
    "    (113, 'fathmm-XF_coding_pred', 'D/N'),\n",
    "    (114, 'Eigen-raw_coding', '+'),\n",
    "    (117, 'Eigen-PC-raw_coding', '+'),\n",
    "    (120, 'GenoCanyon_score', '+'),\n",
    "    (122, 'integrated_fitCons_score', '+')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_average_score(content, symbol):\n",
    "    arr = []\n",
    "    for field in content.split(';'):\n",
    "        try:\n",
    "            arr.append(float(field))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    if arr:\n",
    "        mean = np.mean(arr)\n",
    "        if symbol == '-':\n",
    "            mean = - mean \n",
    "        return mean\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def calc_consensus_prediction(content, del_neu_symbols):\n",
    "    del_symbols, neu_symbols = del_neu_symbols.split('/')\n",
    "    del_preds = np.sum([content.count(s) for s in del_symbols])\n",
    "    neu_preds = np.sum([content.count(s) for s in neu_symbols])\n",
    "    if del_preds > neu_preds:\n",
    "        return 1\n",
    "    elif del_preds == neu_preds:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# recover SAV coordinates from Integrated Datasets and relative indexes\n",
    "ID_SAVs = {}\n",
    "for array_index, SAV in enumerate(ID['SAV_coords']):\n",
    "    Uniprot_acc = SAV.split()[0]\n",
    "    d = ID_SAVs.get(Uniprot_acc, {})\n",
    "    d[SAV] = array_index\n",
    "    ID_SAVs[Uniprot_acc] = d\n",
    "\n",
    "# define a structured array that will contain the output \n",
    "output_dtype = [('SAV_coords', 'U50'), ('chr', 'U2')]\n",
    "for col, method, symbols in dbNSFP_sel_columns:\n",
    "    if symbols in ['+', '-']:\n",
    "       output_dtype.append((f'{symbols}{method}', 'f4')) \n",
    "    else:\n",
    "       output_dtype.append((method, 'i'))\n",
    "output = np.empty(len(ID), dtype=np.dtype(output_dtype))\n",
    "# initialize output array\n",
    "output['SAV_coords'] = ID['SAV_coords']\n",
    "output['chr'] = ''\n",
    "for field in output.dtype.names[2:]:\n",
    "    if field.startswith('+') or field.startswith('-'):\n",
    "        output[field] = np.nan\n",
    "    else:\n",
    "        output[field] = -1\n",
    "\n",
    "# list of input files\n",
    "gz_files = glob(os.path.join(dbNSFP_dir, 'dbNSFP4.0a_variant.chr*.gz'))\n",
    "assert gz_files, 'No file found'\n",
    "\n",
    "# loop over compressed files\n",
    "for gz_file in gz_files:\n",
    "    fname = os.path.basename(gz_file)\n",
    "    chromosome = fname.replace('dbNSFP4.0a_variant.chr', '')\n",
    "    chromosome = chromosome.replace('.gz', '')\n",
    "    print('>>>', fname)\n",
    "    with gzip.open(gz_file, 'rt') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            cols = line.split('\\t')\n",
    "            accs = cols[16].split(';')\n",
    "            # check if Uniprot acc. number is in ID\n",
    "            for j, acc in enumerate(accs):\n",
    "                if acc in ID_SAVs:\n",
    "                    pos = cols[11].split(';')[j]\n",
    "                    waa = cols[4]\n",
    "                    maa = cols[5]\n",
    "                    SAV = f'{acc} {pos} {waa} {maa}'\n",
    "                    # check if specific SAV is in ID\n",
    "                    if SAV in ID_SAVs[acc]:\n",
    "                        arr_i = ID_SAVs[acc][SAV]\n",
    "                        output[arr_i]['chr'] = chromosome\n",
    "                        # recover predictions from selected methods\n",
    "                        for k, t in enumerate(dbNSFP_sel_columns):\n",
    "                            col, method, s = t\n",
    "                            l = cols[col-1]\n",
    "                            if s in ['+', '-']:\n",
    "                                x = calc_average_score(l, s)\n",
    "                            else:\n",
    "                                x = calc_consensus_prediction(l, s)\n",
    "                            output[arr_i][k+2] = x\n",
    "                        break\n",
    "\n",
    "# save output to file\n",
    "np.save('imported_dbNSFP_predictions.npy', output)\n",
    "\n",
    "n_recovered = sum(output['chr'] != '')\n",
    "n_tot = len(output)\n",
    "print(f'{n_recovered} out of {n_tot} SAVs in Rhapsody ID '\n",
    "      'recovered from dbNSFP.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
