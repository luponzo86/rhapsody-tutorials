{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of EGFR mutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle, csv, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, insert here local path to Rhapsody folder with the command:\n",
    "# sys.path.insert(0, '/LOCAL_PATH/rhapsody/')\n",
    "import rhapsody as rhaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Dataset\n",
    "Let's import the training dataset. We will only consider variants in the Integrated Dataset with at least 1 ClinVar review star, if present, and an associated PDB structure larger than 150 residues, two restrictions that we found to improve prediction accuracy (see tutorial `RF_optimization` for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('SAV_coords', '<U50'), ('Uniprot2PDB', '<U100'), ('PDB_length', '<i2'), ('true_label', '<i2'), ('ANM_MSF-chain', '<f4'), ('ANM_MSF-reduced', '<f4'), ('ANM_MSF-sliced', '<f4'), ('ANM_effectiveness-chain', '<f4'), ('ANM_effectiveness-reduced', '<f4'), ('ANM_effectiveness-sliced', '<f4'), ('ANM_sensitivity-chain', '<f4'), ('ANM_sensitivity-reduced', '<f4'), ('ANM_sensitivity-sliced', '<f4'), ('BLOSUM', '<f4'), ('Delta_PSIC', '<f4'), ('Delta_SASA', '<f4'), ('EVmut-DeltaE_epist', '<f4'), ('EVmut-DeltaE_indep', '<f4'), ('EVmut-mut_aa_freq', '<f4'), ('EVmut-wt_aa_cons', '<f4'), ('GNM_MSF-chain', '<f4'), ('GNM_MSF-reduced', '<f4'), ('GNM_MSF-sliced', '<f4'), ('GNM_effectiveness-chain', '<f4'), ('GNM_effectiveness-reduced', '<f4'), ('GNM_effectiveness-sliced', '<f4'), ('GNM_sensitivity-chain', '<f4'), ('GNM_sensitivity-reduced', '<f4'), ('GNM_sensitivity-sliced', '<f4'), ('SASA', '<f4'), ('SASA_in_complex', '<f4'), ('entropy', '<f4'), ('ranked_MI', '<f4'), ('stiffness-chain', '<f4'), ('stiffness-reduced', '<f4'), ('stiffness-sliced', '<f4'), ('wt_PSIC', '<f4')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the numpy structured array containing precomputed features for the optimized training dataset\n",
    "ID = np.load('../00-Training_Dataset/local/data/precomputed_features-ID_opt.npy')\n",
    "ID.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-training of unbiased classifier\n",
    "\n",
    "A few EGFR mutations are found in the Integrated Dataset used for training. In order to get completely unbiased predictions, we will retrain a classifier by excluding those variants from the training dataset.\n",
    "\n",
    "**NB:** The Uniprot ID for gene EGFR is `P00533`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 known deleterious EGFR SAVs:\n",
      "['P00533 748 R T' 'P00533 787 Q R' 'P00533 873 G E']\n",
      "\n",
      "5 known neutral EGFR SAVs:\n",
      "['P00533 266 P R' 'P00533 521 R K' 'P00533 962 R G' 'P00533 98 R Q'\n",
      " 'P00533 988 H P']\n"
     ]
    }
   ],
   "source": [
    "known_EGFR_SAVs = ID[ [SAV.startswith('P00533') for SAV in ID['SAV_coords']] ]\n",
    "\n",
    "known_del_SAVs = known_EGFR_SAVs[ known_EGFR_SAVs['true_label'] == 1 ]\n",
    "known_neu_SAVs = known_EGFR_SAVs[ known_EGFR_SAVs['true_label'] == 0 ]\n",
    "\n",
    "print(f'{len(known_del_SAVs)} known deleterious EGFR SAVs:')\n",
    "print(known_del_SAVs['SAV_coords'])\n",
    "print(f'\\n{len(known_neu_SAVs)} known neutral EGFR SAVs:')\n",
    "print(known_neu_SAVs['SAV_coords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's exclude these variants from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20353"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_subset = ID[ [not SAV.startswith('P00533') for SAV in ID['SAV_coords']] ]\n",
    "len(ID_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this subset of the Integrated Dataset to train unbiased versions of Rhapsody classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featsets = {\n",
    "    'full_clsf': [ 'wt_PSIC', 'Delta_PSIC', 'SASA', \n",
    "                   'ANM_MSF-chain', 'ANM_effectiveness-chain', 'ANM_sensitivity-chain',\n",
    "                   'stiffness-chain', 'entropy', 'ranked_MI', 'BLOSUM' ],\n",
    "    'redx_clsf': [ 'wt_PSIC', 'Delta_PSIC', 'SASA', \n",
    "                   'ANM_MSF-chain', 'ANM_effectiveness-chain', 'ANM_sensitivity-chain',\n",
    "                   'stiffness-chain', 'BLOSUM' ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('local'):\n",
    "    os.mkdir('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers already trained.\n"
     ]
    }
   ],
   "source": [
    "from prody import LOGGER\n",
    "\n",
    "if os.path.isdir('local/results'):\n",
    "    print('Classifiers already trained.')\n",
    "else:\n",
    "    os.mkdir('local/results/')\n",
    "    \n",
    "    LOGGER.start('local/results/RF_training.log')\n",
    "    summaries = {}\n",
    "    \n",
    "    for clsf_version, featset in featsets.items():\n",
    "        folder = f'local/results/{clsf_version}'\n",
    "        os.mkdir(folder)\n",
    "        \n",
    "        f = ['SAV_coords', 'true_label'] + featset\n",
    "        output_dict = rhaps.trainRFclassifier(ID_subset[f])\n",
    "        summaries[clsf_version] = output_dict['CV summary']\n",
    "        \n",
    "        for file in glob.glob('*png') + ['trained_classifier.pkl',]:\n",
    "            os.rename(file, os.path.join(folder, file))\n",
    "            \n",
    "        LOGGER.info('')\n",
    "                    \n",
    "    # store training summary into pickle\n",
    "    pickle.dump(summaries, open('local/results/summaries.pkl', 'wb'))\n",
    "\n",
    "    LOGGER.close('local/results/RF_training.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhapsody predictions\n",
    "We perform a complete scanning of all amino acid variants (*in silico* saturation mutagenesis).\n",
    "\n",
    "**NB:** PolyPhen-2 predictions are precomputed and saved in `data/pph2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed predictions found.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('local/results/predictions'):\n",
    "    print('Precomputed predictions found.')\n",
    "    rh = pickle.load(open('local/results/predictions/rhapsody-pickle.pkl', 'rb'))\n",
    "else:\n",
    "    os.mkdir('local/results/predictions')\n",
    "    # run rhapsody\n",
    "    rh = rhaps.rhapsody('data/pph2/pph2-full.txt', 'local/results/full_clsf/trained_classifier.pkl',\n",
    "                        aux_classifier='local/results/redx_clsf/trained_classifier.pkl', input_type='PP2')\n",
    "    # store files\n",
    "    for f in glob.glob('rhapsody-*.*'):\n",
    "        os.rename(f, os.path.join('local/results/predictions', f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of dimerization on predictions: the kinase domain\n",
    "We will compare predictions obatined by using a custom PDB structure with those obtained automatically by Rhapsody. \n",
    "In particular we will consider the *biological assembly* for the EGFR kinase domain, which is an asymmetric dimer that can be found in the PDB database. \n",
    "We will also consider different ways of including environmental effects (*reduced* vs *sliced* models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimer_pdb_file = 'data/2gs6-dimer.pdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed predictions found.\n",
      "Precomputed predictions found.\n",
      "Precomputed predictions found.\n"
     ]
    }
   ],
   "source": [
    "rh_dimer = {}\n",
    "\n",
    "for env_model in ['chain', 'reduced', 'sliced']:\n",
    "    folder = f'local/results/predictions_dimer-{env_model}'\n",
    "    if os.path.isdir(folder):\n",
    "        print('Precomputed predictions found.')\n",
    "        rh_dimer[env_model] = pickle.load(open(os.path.join(folder, 'rhapsody-pickle.pkl'), 'rb'))\n",
    "    else:\n",
    "        os.mkdir(folder)\n",
    "        # run rhapsody\n",
    "        _r = rhaps.rhapsody('data/pph2/pph2-full.txt', 'local/results/full_clsf/trained_classifier.pkl',\n",
    "                            aux_classifier='local/results/redx_clsf/trained_classifier.pkl', input_type='PP2',\n",
    "                            custom_PDB=dimer_pdb_file, force_env=env_model)\n",
    "        rh_dimer[env_model] = _r\n",
    "        # store files\n",
    "        for f in glob.glob('rhapsody-*.*'):\n",
    "            os.rename(f, os.path.join(folder, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Rhapsody   chain    reduced   sliced\n",
      "Rhapsody    1.000     0.731     0.729     0.735     \n",
      "chain       0.731     1.000     0.986     0.937     \n",
      "reduced     0.729     0.986     1.000     0.933     \n",
      "sliced      0.735     0.937     0.933     1.000     \n"
     ]
    }
   ],
   "source": [
    "# correlation between predictions\n",
    "\n",
    "from scipy.stats.stats import spearmanr\n",
    "\n",
    "sel1 = ~np.isnan(rh_dimer['chain'].mixPreds['score'])\n",
    "sel2 = [x.startswith('3GOP') for x in rh.Uniprot2PDBmap['PDB SAV coords']]\n",
    "sel = np.logical_and(sel1, sel2)\n",
    "\n",
    "pred_sets = [('Rhapsody', rh), ('chain', rh_dimer['chain']), \n",
    "             ('reduced', rh_dimer['reduced']), ('sliced', rh_dimer['sliced'])]\n",
    "\n",
    "print(\" \"*11 + f\"Rhapsody   chain    reduced   sliced\")\n",
    "\n",
    "for (s_i, r_i) in pred_sets:\n",
    "    print(f'{s_i:12}', end='')\n",
    "    for (s_j, r_j) in pred_sets:\n",
    "        rho = spearmanr(r_i.mixPreds['score'][sel], r_j.mixPreds['score'][sel])\n",
    "        print(f'{rho[0]:5.3f}', end=' '*5)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions of known SAVs in the Integrated Dataset\n",
    "The original Integrated Dataset contains a few EGFR variants with clinical interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_infos = np.load('../00-Training_Dataset/local/data/Integrated_Dataset-SAVs.npy')\n",
    "known_SAVs = ID_infos[ [s.startswith('P00533') for s in ID_infos['SAV_coords']] ]\n",
    "len(known_SAVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAV                Rhapsody/chain/reduced/sliced   true_labels\n",
      "P00533 98 R Q        neu    ?      ?      ?        0  humsavar[0]\n",
      "P00533 266 P R       neu    ?      ?      ?        0  humsavar[0],swissvar[0]\n",
      "P00533 428 G D       del    ?      ?      ?        1  humsavar[1],clinvar[1]\n",
      "P00533 521 R K       neu    ?      ?      ?        0  humsavar[0],humvar[0],clinvar[0]**\n",
      "P00533 674 V I       neu    ?      ?      ?        0  humsavar[0],swissvar[0]\n",
      "P00533 709 E A       del    neu    p.neu  p.neu   -1  humsavar[0],varibench[1],clinvar[0]*\n",
      "P00533 709 E G       del    del    del    del     -1  humsavar[0],swissvar[1],clinvar[0]*\n",
      "P00533 709 E K       p.del  neu    neu    neu     -1  humsavar[0],varibench[1],clinvar[0]\n",
      "P00533 719 G A       del    del    del    del     -1  humsavar[0],varibench[1],clinvar[1]*\n",
      "P00533 719 G C       del    del    del    del     -1  humsavar[0],swissvar[1],varibench[1],clinvar[1]\n",
      "P00533 719 G D       del    del    del    del     -1  humsavar[0],varibench[1]\n",
      "P00533 719 G S       del    del    del    del     -1  humsavar[0],clinvar[1]*\n",
      "P00533 724 G S       del    del    del    del     -1  humsavar[0],varibench[1]\n",
      "P00533 734 E K       del    neu    neu    neu     -1  humsavar[0],varibench[1]\n",
      "P00533 748 R T       neu    ?      ?      ?        1  swissvar[1]\n",
      "P00533 768 S I       del    del    del    del     -1  humsavar[0],clinvar[1]*\n",
      "P00533 769 V M       p.neu  neu    neu    neu      0  humsavar[0],clinvar[0]\n",
      "P00533 787 Q R       del    del    del    del      1  varibench[1]\n",
      "P00533 790 T M       del    del    del    del     -1  humsavar[0],varibench[1],clinvar[1]***\n",
      "P00533 833 L V       neu    neu    neu    neu      0  humsavar[0],clinvar[0]\n",
      "P00533 834 V L       del    p.neu  neu    del     -1  humsavar[0],clinvar[1]*\n",
      "P00533 835 H L       del    del    del    del     -1  humsavar[0],swissvar[1],clinvar[0]\n",
      "P00533 838 L V       del    del    del    del      0  humsavar[0],clinvar[0]\n",
      "P00533 858 L M       p.del  del    del    del     -1  humsavar[0],clinvar[1]*\n",
      "P00533 858 L R       del    del    del    del     -1  humsavar[0],clinvar[1]***\n",
      "P00533 861 L Q       del    del    del    del     -1  humsavar[0],varibench[1],clinvar[1]\n",
      "P00533 873 G E       neu    neu    neu    neu      1  varibench[1]\n",
      "P00533 962 R G       p.neu  neu    neu    neu      0  humsavar[0]\n",
      "P00533 988 H P       neu    neu    neu    neu      0  exovar[0],humsavar[0],humvar[0],clinvar[0]*\n",
      "P00533 1034 L R      ?      ?      ?      ?        0  humsavar[0],swissvar[0]\n",
      "P00533 1048 A V      ?      ?      ?      ?        0  exovar[0]\n",
      "P00533 1210 A V      ?      ?      ?      ?        0  humsavar[0],swissvar[0]\n"
     ]
    }
   ],
   "source": [
    "# comparison with 'true_labels' found in the Integrated Dataset\n",
    "\n",
    "abbrv = {'?': '?', 'neutral': 'neu', 'prob.neutral': 'p.neu',\n",
    "         'deleterious': 'del', 'prob.delet.': 'p.del'}\n",
    "\n",
    "print(f\"SAV                Rhapsody/chain/reduced/sliced   true_labels\")\n",
    "\n",
    "for i, s in enumerate(rh.SAVcoords['text']):\n",
    "    # Rhapsody predictions\n",
    "    preds = \"\"\n",
    "    for SAV in known_SAVs:\n",
    "        if s == SAV['SAV_coords']:\n",
    "            for r in [rh, rh_dimer['chain'], rh_dimer['reduced'], rh_dimer['sliced']]:\n",
    "                p = r.mixPreds[i]['path. class']\n",
    "                preds += f\"{abbrv[p]:6} \" \n",
    "            if SAV['ClinVar_review_star'] != -1:\n",
    "                stars = \"*\" * SAV['ClinVar_review_star']\n",
    "            else:\n",
    "                stars = \"\"\n",
    "            print(f\"{SAV['SAV_coords']:20} {preds} {SAV['true_label']:2}  {SAV['datasets']}{stars}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures\n",
    "We can plot the average predictions on the PDB structures to highlight the differences between the various approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('local/figures'):\n",
    "    os.mkdir('local/figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> PDB file is found in the local folder (/home/lponzoni/.../3gop.pdb.gz).\n",
      "@> 2385 atoms and 1 coordinate set(s) were parsed in 0.03s.\n",
      "@> 9984 atoms and 1 coordinate set(s) were parsed in 0.09s.\n",
      "@> 9984 atoms and 1 coordinate set(s) were parsed in 0.09s.\n",
      "@> 9984 atoms and 1 coordinate set(s) were parsed in 0.09s.\n"
     ]
    }
   ],
   "source": [
    "for case in ['Rhapsody', 'chain', 'reduced', 'sliced']:\n",
    "    if case == 'Rhapsody':\n",
    "        PDBID = '3GOP'\n",
    "        r = rh\n",
    "        pdb = prody.parsePDB('3GOP')\n",
    "    else:\n",
    "        PDBID = '2gs6'\n",
    "        r = rh_dimer[case]\n",
    "        pdb = prody.parsePDB(dimer_pdb_file)\n",
    "        \n",
    "    probs = {} \n",
    "    for U2PDBmap, pred in zip(r.Uniprot2PDBmap['PDB SAV coords'], \n",
    "                              r.mixPreds['path. probability']):\n",
    "        if not U2PDBmap.startswith(PDBID):\n",
    "            continue\n",
    "        res = int(U2PDBmap.split()[2])\n",
    "        probs.setdefault(res, [])\n",
    "        probs[res].append(pred)\n",
    "\n",
    "    PDBresids = pdb.getResnums()\n",
    "    new_betas = np.zeros_like(PDBresids, dtype=float)\n",
    "    for i, res in enumerate(PDBresids):\n",
    "        if res in probs:\n",
    "            x = np.nanmean(probs[res])\n",
    "            beta = -1 if np.isnan(x) else x\n",
    "        else:\n",
    "            beta = -1\n",
    "        new_betas[i] = beta\n",
    "    # write modified PDB\n",
    "    pdb.setBetas(new_betas)\n",
    "    f = prody.writePDB(f'local/figures/{case}-mapped', pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
