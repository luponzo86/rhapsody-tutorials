{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of RAS saturation mutagenesis data\n",
    "\n",
    "In the following we compare predictions from Rhapsody, PolyPhen-2 and EVmutation against experimental functional assessments of RAS mutants presented in:\n",
    "[Bandaru P et al, *Deconstruction of the Ras switching cycle through saturation mutagenesis*, Elife (2017)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5538825/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle, csv, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert here local path to Rhapsody folder\n",
    "sys.path.insert(0, '../../rhapsody/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-training of unbiased classifier\n",
    "\n",
    "A few RAS mutations are found in the Integrated Dataset used for training. In order to get completely unbiased predictions, we will retrain a classifier by excluding those variants from the training dataset.\n",
    "\n",
    "**NB:** The Uniprot names for gene HRAS are `P01112` or `RASH_HUMAN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhapsody import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 known deleterious RAS SAVs:\n",
      "['P01112 117 K R', 'P01112 12 G A', 'P01112 12 G C', 'P01112 12 G D', 'P01112 12 G E', 'P01112 12 G S', 'P01112 12 G V', 'P01112 13 G C', 'P01112 13 G D', 'P01112 13 G R', 'P01112 146 A T', 'P01112 146 A V', 'P01112 22 Q K', 'P01112 58 T I', 'P01112 61 Q K', 'P01112 61 Q L', 'P01112 63 E K']\n",
      "\n",
      "0 known neutral RAS SAVs:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "ID = np.load('../00-Training_Dataset/data/Integrated_Dataset-SAVs.npy')\n",
    "\n",
    "ID_del = ID[ID['true_label']==1]\n",
    "ID_neu = ID[ID['true_label']==0]\n",
    "\n",
    "known_del_SAVs = [SAV['SAV_coords'] for SAV in ID_del if SAV['SAV_coords'].startswith('P01112')]\n",
    "known_neu_SAVs = [SAV['SAV_coords'] for SAV in ID_neu if SAV['SAV_coords'].startswith('P01112')]\n",
    "\n",
    "print(f'{len(known_del_SAVs)} known deleterious RAS SAVs:')\n",
    "print(known_del_SAVs)\n",
    "print(f'\\n{len(known_neu_SAVs)} known neutral RAS SAVs:')\n",
    "print(known_neu_SAVs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's exclude these variants from the dataset. \n",
    "\n",
    "We will also only consider variants with at least 1 ClinVar review star, if present, and an associated PDB structure larger than 150 residues, two restrictions that we found to improve prediction accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_subset = ID[ [i for i,SAV in enumerate(ID) if not SAV['SAV_coords'].startswith('P01112') \n",
    "                                                 and SAV['PDB_length']>=150] ]\n",
    "len(ID_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete set of Rhapsody features\n",
    "full_clsf_featset = ['SAV_coords', 'true_label', \n",
    "                     'wt_PSIC', 'Delta_PSIC', 'SASA', 'ANM_MSF-chain', \n",
    "                     'ANM_effectiveness-chain', 'ANM_sensitivity-chain',\n",
    "                     'stiffness-chain', 'entropy', 'ranked_MI', 'BLOSUM']\n",
    "# reduced set of Rhapsody features (without features computed on Pfam domains)\n",
    "redx_clsf_featset = [f for f in full_clsf_featset if f not in ['entropy', 'ranked_MI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('results'):\n",
    "    os.mkdir('results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training of full classifier\n",
    "if os.path.isdir('results/full_clsf'):\n",
    "    print('full classifier already trained')\n",
    "else:\n",
    "    os.mkdir('results/full_clsf')\n",
    "    full_clsf = trainRFclassifier(ID_subset[full_clsf_featset])\n",
    "    for file in glob.glob('*png') + ['trained_classifier.pkl',]:\n",
    "        os.rename(file, os.path.join('results/full_clsf', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training of reduced classifier\n",
    "if os.path.isdir('results/redx_clsf'):\n",
    "    print('reduced classifier already trained')\n",
    "else:\n",
    "    os.mkdir('results/redx_clsf')\n",
    "    redx_clsf = trainRFclassifier(ID_subset[redx_clsf_featset])\n",
    "    for file in glob.glob('*png') + ['trained_classifier.pkl',]:\n",
    "        os.rename(file, os.path.join('results/redx_clsf', file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhapsody predictions\n",
    "We perform a complete scanning of all amino acid variants (*in silico* saturation mutagenesis).\n",
    "\n",
    "**NB:** PolyPhen-2 predictions are precomputed and saved in `data/pph2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isdir('results/predictions'):\n",
    "    print('predictions already precomputed')\n",
    "    rh = pickle.load(open('results/predictions/rhapsody-pickle.pkl', 'rb'))\n",
    "else:\n",
    "    os.mkdir('results/predictions')\n",
    "    # run rhapsody\n",
    "    rh = rhapsody('data/pph2/pph2-full.txt', 'results/full_clsf/trained_classifier.pkl',\n",
    "                  aux_classifier='results/redx_clsf/trained_classifier.pkl', input_type='PP2')\n",
    "    # store files\n",
    "    for f in glob.glob('rhapsody-*.*'):\n",
    "        os.rename(f, os.path.join('results/predictions', f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active *vs* inactive state\n",
    "Rhapsody automatically maps most variants onto PDB `4Q21`, which is the GDP-complexed **inactive** structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDBIDs = [l['PDB SAV coords'][:4] for l in rh.Uniprot2PDBmap if l['PDB size']!=0]\n",
    "for PDBID in set(PDBIDs):\n",
    "    print(PDBID, PDBIDs.count(PDBID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can force Rhapsody to use, for instance, the **active** (GTP-bound) structure `6Q21` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('results/predictions_2'):\n",
    "    print('predictions already precomputed')\n",
    "    rh_2 = pickle.load(open('results/predictions_2/rhapsody-pickle.pkl', 'rb'))\n",
    "else:\n",
    "    os.mkdir('results/predictions_2')\n",
    "    # run rhapsody\n",
    "    rh_2 = rhapsody('data/pph2/pph2-full.txt', 'results/full_clsf/trained_classifier.pkl',\n",
    "                    aux_classifier='results/redx_clsf/trained_classifier.pkl', input_type='PP2', custom_PDB='6Q21')\n",
    "    # store files\n",
    "    for f in glob.glob('rhapsody-*.*'):\n",
    "        os.rename(f, os.path.join('results/predictions_2', f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of predictions: active *vs* inactive state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('figures'):\n",
    "    os.mkdir('figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import spearmanr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_inactive = rh.mixPreds['score']\n",
    "score_active   = rh_2.mixPreds['score']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(score_inactive, score_active, marker='.')\n",
    "ax.set_xlabel('score for inactive state (PDBID: 4Q21)')\n",
    "ax.set_ylabel('score for active state (PDBID: 6Q21)')\n",
    "\n",
    "sel = np.logical_and(~np.isnan(score_inactive), ~np.isnan(score_active))\n",
    "rho = spearmanr(score_inactive[sel], score_active[sel])[0]\n",
    "\n",
    "s = r'$\\rho$'\n",
    "ax.set_title('RHAPSODY predictions on active/inactive state')\n",
    "ax.text(0.8, 0.1, f'{s} = {rho:5.3f}')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'figures/active_vs_inactive_correlation.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, predictions based on inactive *vs* active conformations are very similar. We can plot the residue-averaged prediction profiles on the respective structure to better highlight differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from prody import *\n",
    "\n",
    "avg_prob = {}\n",
    "\n",
    "# inactive conformation\n",
    "_p = rh.mixPreds['path. probability']\n",
    "_m = _p.reshape((-1, 19)).T\n",
    "avg_prob['inactive'] = np.nanmean(_m, axis=0)\n",
    "# active conformation\n",
    "_p = rh_2.mixPreds['path. probability']\n",
    "_m = _p.reshape((-1, 19)).T\n",
    "avg_prob['active'] = np.nanmean(_m, axis=0)\n",
    "# difference between inactive and active profiles\n",
    "avg_prob['difference'] = avg_prob['active'] - avg_prob['inactive']\n",
    "\n",
    "# residue numbers\n",
    "resids = rh.SAVcoords['pos'].reshape((-1, 19)).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import PDB structures\n",
    "pdbs = {}\n",
    "pdbs['inactive']   = parsePDB('4q21', chain='A').select('protein and resid 2 to 166')\n",
    "pdbs['active']     = parsePDB('6q21', chain='A').select('protein and resid 2 to 166')\n",
    "pdbs['difference'] = pdbs['active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in ['inactive', 'active', 'difference']:\n",
    "    pdb = pdbs[case]\n",
    "    # replace the B-factor column in chain A with the predictions\n",
    "    PDBresids = pdb.getResnums()\n",
    "    new_betas = np.zeros_like(PDBresids, dtype=float)\n",
    "    for resid, prob in zip(resids, avg_prob[case]):\n",
    "        if np.isnan(prob):\n",
    "            prob = 0\n",
    "        new_betas[PDBresids==int(resid)] = prob\n",
    "    # write modified PDB\n",
    "    pdb.setBetas(new_betas)\n",
    "    f = writePDB(f'figures/mapped_pdb-{case}', pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of difference values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "diff = avg_prob['difference']\n",
    "plt.hist(diff[~np.isnan(diff)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with experimental results from Bandaru et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from file\n",
    "data = {}\n",
    "\n",
    "for f in glob.glob('data/*csv'):\n",
    "    fname = os.path.basename(f, )\n",
    "    case = fname.replace('.csv', '')\n",
    "    with open(f, 'r') as _f:\n",
    "        reader = csv.reader(_f)\n",
    "        data[case] = list(reader)\n",
    "        \n",
    "exp_sequence = ''.join(data['attenuated_RAS'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** The sequence used in the experiments is a substring of the Uniprot sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prody import queryUniprot\n",
    "\n",
    "acc = 'P01112'\n",
    "sequence = queryUniprot(acc)['sequence   0'].replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Uniprot sequence length:', len(sequence))\n",
    "print('Exp. sequence length:   ', len(exp_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_sequence == sequence[1: len(exp_sequence)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to dictionary\n",
    "tables = {}\n",
    "\n",
    "for case, d in data.items():\n",
    "    resids = d[0][1:]\n",
    "    wt_aas = d[1][1:]\n",
    "    table = {}\n",
    "    for line in d[2:]:\n",
    "        mut_aa = line[0]\n",
    "        for i, x in enumerate(line[1:]):\n",
    "            resid = int(resids[i])\n",
    "            wt_aa = wt_aas[i]\n",
    "            table[f'P01112 {resid} {wt_aa} {mut_aa}'] = float(x)\n",
    "    tables[case] = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put exp. data in array form and in the same order as Rhapsody predictions\n",
    "SAV_coords = rh.SAVcoords['text']\n",
    "\n",
    "exp_scores = {}\n",
    "for case, table in tables.items():\n",
    "    a = np.zeros(len(SAV_coords))\n",
    "    a[:] = np.nan\n",
    "    for i, SAV in enumerate(SAV_coords):\n",
    "        if SAV in table:\n",
    "            a[i] = table[SAV]\n",
    "    exp_scores[case] = a\n",
    "\n",
    "# compute residue-averaged functional effects\n",
    "avg_exp_scores = {}\n",
    "for case, exp_score in exp_scores.items():\n",
    "    avg_exp_scores[case] = np.nanmean(exp_score.reshape((-1, 19)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computational scores\n",
    "rhaps_score_inac = rh.mixPreds['score']\n",
    "rhaps_score_actv = rh_2.mixPreds['score']\n",
    "PP2_probs = np.array([float(x) for x in rh.PP2output['pph2_prob']])\n",
    "EVmut_score = - np.array([float(x) for x in rh.calcEVmutationFeats()['EVmut-DeltaE_epist']])\n",
    "\n",
    "methods = ['Rhapsody (inactive state)', 'Rhapsody (active state)', 'EVmutation', 'PolyPhen-2']\n",
    "\n",
    "comput_scores = {\n",
    "  'Rhapsody (inactive state)': rhaps_score_inac, \n",
    "  'Rhapsody (active state)' :  rhaps_score_actv, \n",
    "  'EVmutation' :               EVmut_score, \n",
    "  'PolyPhen-2' :               PP2_probs\n",
    "}\n",
    "\n",
    "# compute residue-averaged computational scores\n",
    "avg_comput_scores = {}\n",
    "for method, score in comput_scores.items():\n",
    "    avg_comput_scores[method] = np.nanmean(score.reshape((-1, 19)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman correlation\n",
    "\n",
    "In the following, we compute and plot the correlation between experimental measurements and computational predictions for the functional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in exp_scores:\n",
    "    exp_score     = exp_scores[case]\n",
    "    avg_exp_score = avg_exp_scores[case]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15,4))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        method = methods[i]\n",
    "        # individual fitness scores\n",
    "        cs = comput_scores[method]\n",
    "        ax.scatter(exp_score, cs, marker='.')\n",
    "        sel = np.logical_and(~np.isnan(exp_score), ~np.isnan(cs))\n",
    "        rho = spearmanr(exp_score[sel], cs[sel])[0]\n",
    "        # residue-averaged fitness scores\n",
    "        acs = avg_comput_scores[method]\n",
    "        ax.scatter(avg_exp_score, acs, marker='.', c='r')\n",
    "        sel = np.logical_and(~np.isnan(avg_exp_score), ~np.isnan(acs))\n",
    "        rho_av = spearmanr(avg_exp_score[sel], acs[sel])[0]\n",
    "        # print labels\n",
    "        ax.set_ylabel(method)\n",
    "        s = r'$\\rho$'\n",
    "        ax.set_title(f'{case[:-4]}: {s}={rho:5.2f} (avg: {rho_av:5.2f})')\n",
    "        ax.set_xlim((-1.25, 0.7))\n",
    "        ax.set_xlabel('exp. ΔE')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f'figures/correlation-{case}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the goal of Rhapsody is to identify mutations that impair the normal activity and interactions of proteins, specifically by taking into account changes to their internal structural dynamics, we can focus on the \"regulated\" case (its \"wild-type\" context) among those presented in the paper.\n",
    "From the plots in the first line, we see that Rhapsody (computed on both inactive and active states) performs in general better than both EVmutation and PolyPhen-2. \n",
    "\n",
    "### ROCs, Precision-Recall curves and other metrics\n",
    "\n",
    "We can also obtain a binary classification from the distribution of functional effects by setting a cutoff according to what is considered a \"significant loss of function\". We will choose the median as cutoff. This allows us to compute ROC and Precision-Recall curves and compare performances based on different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_qs = [40, 50, 60]\n",
    "cutoff_qs.sort()\n",
    "\n",
    "cutoffs = {}\n",
    "avg_cutoffs = {}\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15,8))\n",
    "\n",
    "for i, case in enumerate(exp_scores):\n",
    "    exp_score = exp_scores[case]\n",
    "    exp_score = exp_score[~np.isnan(exp_score)]\n",
    "    avg_exp_score = avg_exp_scores[case]\n",
    "    avg_exp_score = avg_exp_score[~np.isnan(avg_exp_score)]\n",
    "    \n",
    "    # cutoff definitions\n",
    "    cutoffs[case]     = {q: np.nanpercentile(exp_score, q) for q in cutoff_qs}\n",
    "    avg_cutoffs[case] = {q: np.nanpercentile(avg_exp_score, q) for q in cutoff_qs}\n",
    "    \n",
    "    ax1 = axes[0, i]\n",
    "    ax2 = axes[1, i]\n",
    "    \n",
    "    ax1.hist(exp_score, density=True, bins='auto')\n",
    "    ax2.hist(avg_exp_score, density=True, bins='auto', color='red')\n",
    "    for q in cutoff_qs:\n",
    "        cutoff     = cutoffs[case][q]\n",
    "        avg_cutoff = avg_cutoffs[case][q]\n",
    "        if q == cutoff_qs[1]:\n",
    "            ax1.axvline(cutoff, color='k') \n",
    "            ax2.axvline(avg_cutoff, color='k') \n",
    "        else:\n",
    "            ax1.axvline(cutoff, color='k', ls='--') \n",
    "            ax2.axvline(avg_cutoff, color='k', ls='--') \n",
    "    \n",
    "    ax1.set_title(case)\n",
    "    ax2.set_title('(residue-averaged)')\n",
    "    ax1.set_xlim((-1.25, 0.7))\n",
    "    ax2.set_xlim((-1.25, 0.7))\n",
    "    ax2.set_xlabel('exp. ΔE')\n",
    "    \n",
    "axes[0,0].set_ylabel('frequency')\n",
    "axes[1,0].set_ylabel('frequency')\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig(f'figures/histograms-cutoff.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "for case in exp_scores:\n",
    "    \n",
    "    metrics[case] = {}\n",
    "    \n",
    "    # experimental measurements (fitness effects)\n",
    "    exp_score     = exp_scores[case]\n",
    "    avg_exp_score = avg_exp_scores[case]\n",
    "\n",
    "    # loop over computational methods \n",
    "    for method in methods:\n",
    "                      \n",
    "        # individual and residue-averaged computational predictions fitness effects\n",
    "        comput_score = comput_scores[method]\n",
    "        avg_comput_score = avg_comput_scores[method]\n",
    "        \n",
    "        # discard NaN values\n",
    "        sel = np.logical_and(~np.isnan(exp_score), ~np.isnan(comput_score))\n",
    "        avg_sel = np.logical_and(~np.isnan(avg_exp_score), ~np.isnan(avg_comput_score))\n",
    "\n",
    "        m = {}\n",
    "        \n",
    "        # loop over cutoffs for experimental values\n",
    "        for q in cutoff_qs:\n",
    "            cutoff     = cutoffs[case][q]\n",
    "            avg_cutoff = avg_cutoffs[case][q]\n",
    "            \n",
    "            m[q] = {}\n",
    "            \n",
    "            # binary classification and computational score for individual measurements\n",
    "            exp_class = np.where(exp_score[sel] < cutoff, 1, 0)\n",
    "            cs = comput_score[sel]\n",
    "            # curves and metrics\n",
    "            fpr, tpr, _   = roc_curve(exp_class, cs)\n",
    "            prc, rec, _   = precision_recall_curve(exp_class, cs)\n",
    "            m[q]['ROC']   = (fpr, tpr)\n",
    "            m[q]['PRC']   = (prc, rec)\n",
    "            m[q]['AUROC'] = roc_auc_score(exp_class, cs)\n",
    "            m[q]['AUPRC'] = average_precision_score(exp_class, cs)\n",
    "\n",
    "            # binary classification for residue-averaged measurements\n",
    "            exp_class = np.where(avg_exp_score[avg_sel] < avg_cutoff, 1, 0)\n",
    "            cs = avg_comput_score[avg_sel]\n",
    "            # curves and metrics\n",
    "            fpr, tpr, _   = roc_curve(exp_class, cs)\n",
    "            prc, rec, _   = precision_recall_curve(exp_class, cs)\n",
    "            m[q]['avg_ROC']   = (fpr, tpr)\n",
    "            m[q]['avg_PRC']   = (prc, rec)\n",
    "            m[q]['avg_AUROC'] = roc_auc_score(exp_class, cs)\n",
    "            m[q]['avg_AUPRC'] = average_precision_score(exp_class, cs)\n",
    "\n",
    "        metrics[case][method] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in exp_scores:\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15,4))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        method = methods[i]\n",
    "        \n",
    "        m = metrics[case][method]\n",
    "        q0, q1, q2 = cutoff_qs\n",
    "        \n",
    "        # random ROC\n",
    "        ax.plot([0,1], [0,1], '--', color='gray')\n",
    "        \n",
    "        # plot for individual fitness effects\n",
    "        aucs = [m[q]['AUROC'] for q in m.keys()]\n",
    "        l = r'AUC = {:4.2f}$\\pm${:4.2f}'.format(np.mean(aucs), np.std(aucs))\n",
    "        ax.plot(m[q1]['ROC'][0], m[q1]['ROC'][1], 'b-', label=l)\n",
    "        x_dense = np.arange(0,1,.01) \n",
    "        ax.fill_between(x_dense, np.interp(x_dense, m[q0]['ROC'][0], m[q0]['ROC'][1]), \n",
    "                                 np.interp(x_dense, m[q2]['ROC'][0], m[q2]['ROC'][1]), alpha=.5)\n",
    "\n",
    "        # plot for residue-averaged fitness effects\n",
    "        aucs = [m[q]['avg_AUROC'] for q in m.keys()]\n",
    "        l = r'$\\langle$AUC$\\rangle _{res}$ = ' \n",
    "        l += r'{:4.2f}$\\pm${:4.2f}'.format(np.mean(aucs), np.std(aucs)) \n",
    "        ax.plot(m[q1]['avg_ROC'][0], m[q1]['avg_ROC'][1], 'r-', label=l)\n",
    "        x_dense = np.arange(0,1,.01) \n",
    "        ax.fill_between(x_dense, np.interp(x_dense, m[q0]['avg_ROC'][0], m[q0]['avg_ROC'][1]), \n",
    "                                 np.interp(x_dense, m[q2]['avg_ROC'][0], m[q2]['avg_ROC'][1]), alpha=.5)\n",
    "        \n",
    "        # set labels\n",
    "        ax.set_title(f'{case[:-4]} - {method}')   \n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.legend(handlelength=1)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'figures/ROC-{case}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in exp_scores:\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15,4))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        method = methods[i]\n",
    "        \n",
    "        m = metrics[case][method]\n",
    "        q0, q1, q2 = cutoff_qs\n",
    "        \n",
    "        # plot for individual fitness effects\n",
    "        aucs = [m[q]['AUPRC'] for q in cutoff_qs]\n",
    "        l = r'AUC = {:4.2f}$\\pm${:4.2f}'.format(np.mean(aucs), np.std(aucs))\n",
    "        ax.plot(m[q1]['PRC'][0], m[q1]['PRC'][1], 'b-', label=l)\n",
    "\n",
    "        # plot for residue-averaged fitness effects\n",
    "        aucs = [m[q]['avg_AUPRC'] for q in cutoff_qs]\n",
    "        l = r'$\\langle$AUC$\\rangle _{res}$ = ' \n",
    "        l += r'{:4.2f}$\\pm${:4.2f}'.format(np.mean(aucs), np.std(aucs)) \n",
    "        ax.plot(m[q1]['avg_PRC'][0], m[q1]['avg_PRC'][1], 'r-', label=l)\n",
    "        \n",
    "        # set labels\n",
    "        ax.set_title(f'{case[:-4]} - {method}')   \n",
    "        ax.set_xlabel('Recall')\n",
    "        ax.set_ylabel('Precision')\n",
    "        ax.legend(handlelength=1)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'figures/PRC-{case}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we apply an alternative definition of \"deleterious\" variants, that include not only loss-of-function mutations, but also gain-of-function mutations. We can do that by considering as \"positive cases\" those whose difference in fitness with respect to wild-type is greater than a certain threshold, in both directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_qs = [40, 50, 60]\n",
    "threshold_qs.sort()\n",
    "\n",
    "thresholds = {}\n",
    "avg_thresholds = {}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15,8))\n",
    "\n",
    "for i, case in enumerate(exp_scores):\n",
    "    exp_score = exp_scores[case]\n",
    "    exp_score = exp_score[~np.isnan(exp_score)]\n",
    "    avg_exp_score = avg_exp_scores[case]\n",
    "    avg_exp_score = avg_exp_score[~np.isnan(avg_exp_score)]\n",
    "    \n",
    "    # threshold definitions\n",
    "#     thresholds[case]     = {q: q * np.std(exp_score) for q in threshold_qs}\n",
    "#     avg_thresholds[case] = {q: q * np.std(avg_exp_score) for q in threshold_qs}\n",
    "    thresholds[case]     = {q: np.nanpercentile(abs(exp_score), q) for q in cutoff_qs}\n",
    "    avg_thresholds[case] = {q: np.nanpercentile(abs(avg_exp_score), q) for q in cutoff_qs}\n",
    "    \n",
    "    ax1 = axes[0, i]\n",
    "    ax2 = axes[1, i]\n",
    "    \n",
    "    ax1.hist(exp_score, density=True, bins='auto')\n",
    "    ax2.hist(avg_exp_score, density=True, bins='auto', color='red')\n",
    "\n",
    "    for q, ls in zip(threshold_qs, ['--', '-', ':']):\n",
    "        threshold     = thresholds[case][q]\n",
    "        avg_threshold = avg_thresholds[case][q]\n",
    "        ax1.axvline( threshold, color='k', ls=ls) \n",
    "        ax1.axvline(-threshold, color='k', ls=ls) \n",
    "        ax2.axvline( avg_threshold, color='k', ls=ls) \n",
    "        ax2.axvline(-avg_threshold, color='k', ls=ls) \n",
    "    \n",
    "    ax1.set_title(case)\n",
    "    ax2.set_title('(residue-averaged)')\n",
    "    ax1.set_xlim((-1.25, 0.7))\n",
    "    ax2.set_xlim((-1.25, 0.7))\n",
    "    ax2.set_xlabel('exp. ΔE')\n",
    "    \n",
    "axes[0,0].set_ylabel('frequency')\n",
    "axes[1,0].set_ylabel('frequency')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'figures/histograms-threshold.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_2 = {}\n",
    "\n",
    "for case in exp_scores:\n",
    "    \n",
    "    metrics_2[case] = {}\n",
    "    \n",
    "    # experimental measurements (fitness effects)\n",
    "    exp_score     = exp_scores[case]\n",
    "    avg_exp_score = avg_exp_scores[case]\n",
    "\n",
    "    # loop over computational methods \n",
    "    for method in methods:\n",
    "                      \n",
    "        # individual and residue-averaged computational predictions fitness effects\n",
    "        comput_score = comput_scores[method]\n",
    "        avg_comput_score = avg_comput_scores[method]\n",
    "        \n",
    "        # discard NaN values\n",
    "        sel = np.logical_and(~np.isnan(exp_score), ~np.isnan(comput_score))\n",
    "        avg_sel = np.logical_and(~np.isnan(avg_exp_score), ~np.isnan(avg_comput_score))\n",
    "\n",
    "        m = {}\n",
    "        \n",
    "        # loop over thresholds for experimental values\n",
    "        for q in threshold_qs:\n",
    "            threshold     = thresholds[case][q]\n",
    "            avg_threshold = avg_thresholds[case][q]\n",
    "            \n",
    "            m[q] = {}\n",
    "            \n",
    "            # binary classification and computational score for individual measurements\n",
    "            exp_class = np.where(abs(exp_score[sel]) > threshold, 1, 0)\n",
    "            cs = comput_score[sel]\n",
    "            # curves and metrics\n",
    "            fpr, tpr, _   = roc_curve(exp_class, cs)\n",
    "            prc, rec, _   = precision_recall_curve(exp_class, cs)\n",
    "            m[q]['ROC']   = (fpr, tpr)\n",
    "            m[q]['PRC']   = (prc, rec)\n",
    "            m[q]['AUROC'] = roc_auc_score(exp_class, cs)\n",
    "            m[q]['AUPRC'] = average_precision_score(exp_class, cs)\n",
    "\n",
    "\n",
    "            # binary classification for residue-averaged measurements\n",
    "            exp_class = np.where(abs(avg_exp_score[avg_sel]) > avg_threshold, 1, 0)\n",
    "            cs = avg_comput_score[avg_sel]\n",
    "            # curves and metrics\n",
    "            fpr, tpr, _   = roc_curve(exp_class, cs)\n",
    "            prc, rec, _   = precision_recall_curve(exp_class, cs)\n",
    "            m[q]['avg_ROC']   = (fpr, tpr)\n",
    "            m[q]['avg_PRC']   = (prc, rec)\n",
    "            m[q]['avg_AUROC'] = roc_auc_score(exp_class, cs)\n",
    "            m[q]['avg_AUPRC'] = average_precision_score(exp_class, cs)\n",
    "\n",
    "        metrics_2[case][method] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in exp_scores:\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15,4))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        method = methods[i]\n",
    "        \n",
    "        m = metrics_2[case][method]\n",
    "        q0, q1, q2 = threshold_qs\n",
    "        \n",
    "        # random ROC\n",
    "        ax.plot([0,1], [0,1], '--', color='gray')\n",
    "        \n",
    "        # plot for individual fitness effects\n",
    "        aucs = [m[q]['AUROC'] for q in m.keys()]\n",
    "        l = r'AUC = {:4.2f}$\\pm${:4.2f}'.format(np.mean(aucs), np.std(aucs))\n",
    "        ax.plot(m[q1]['ROC'][0], m[q1]['ROC'][1], 'b-', label=l)\n",
    "        x_dense = np.arange(0,1,.01) \n",
    "        ax.fill_between(x_dense, np.interp(x_dense, m[q0]['ROC'][0], m[q0]['ROC'][1]), \n",
    "                                 np.interp(x_dense, m[q2]['ROC'][0], m[q2]['ROC'][1]), alpha=.5)\n",
    "\n",
    "        # plot for residue-averaged fitness effects\n",
    "        aucs = [m[q]['avg_AUROC'] for q in m.keys()]\n",
    "        l = r'$\\langle$AUC$\\rangle _{res}$ = ' \n",
    "        l += r'{:4.2f}$\\pm${:4.2f}'.format(np.mean(aucs), np.std(aucs)) \n",
    "        ax.plot(m[q1]['avg_ROC'][0], m[q1]['avg_ROC'][1], 'r-', label=l)\n",
    "        x_dense = np.arange(0,1,.01) \n",
    "        ax.fill_between(x_dense, np.interp(x_dense, m[q0]['avg_ROC'][0], m[q0]['avg_ROC'][1]), \n",
    "                                 np.interp(x_dense, m[q2]['avg_ROC'][0], m[q2]['avg_ROC'][1]), alpha=.5)\n",
    "        \n",
    "        # set labels\n",
    "        ax.set_title(f'{case[:-4]} - {method}')   \n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.legend(handlelength=1)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'figures/ROC-2-{case}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in exp_scores:\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15,4))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        method = methods[i]\n",
    "        \n",
    "        m = metrics_2[case][method]\n",
    "        q0, q1, q2 = threshold_qs\n",
    "        \n",
    "        # plot for individual fitness effects\n",
    "        aucs = [m[q]['AUPRC'] for q in cutoff_qs]\n",
    "        l = r'AUC = {:4.2f}$\\pm${:4.2f}'.format(np.mean(aucs), np.std(aucs))\n",
    "        ax.plot(m[q1]['PRC'][0], m[q1]['PRC'][1], 'b-', label=l)\n",
    "\n",
    "        # plot for residue-averaged fitness effects\n",
    "        aucs = [m[q]['avg_AUPRC'] for q in cutoff_qs]\n",
    "        l = r'$\\langle$AUC$\\rangle _{res}$ = ' \n",
    "        l += r'{:4.2f}$\\pm${:4.2f}'.format(np.mean(aucs), np.std(aucs)) \n",
    "        ax.plot(m[q1]['avg_PRC'][0], m[q1]['avg_PRC'][1], 'r-', label=l)\n",
    "        \n",
    "        # set labels\n",
    "        ax.set_title(f'{case[:-4]} - {method}')   \n",
    "        ax.set_xlabel('Recall')\n",
    "        ax.set_ylabel('Precision')\n",
    "        ax.legend(handlelength=1)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'figures/PRC-2-{case}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *In silico* saturation mutagenesis table\n",
    "Experimental measurements are reversed to make easier a comparison between residue-averaged profiles on the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_score = - exp_scores['regulated_RAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sat_mutagen_figure('figures/sat_mutagen-inactive-1', rh, other_preds=exp_score, res_interval=(1,95))\n",
    "print_sat_mutagen_figure('figures/sat_mutagen-inactive-2', rh, other_preds=exp_score, res_interval=(95,190))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_sat_mutagen_figure('figures/sat_mutagen-active-1', rh_2, other_preds=exp_score, res_interval=(1,95))\n",
    "print_sat_mutagen_figure('figures/sat_mutagen-active-2', rh_2, other_preds=exp_score, res_interval=(95,190))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the secondary structure and solvent accessible surface area (SASA) in two strips to be paired with the saturation mutagenesis tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute secondary structure and SASA with DSSP\n",
    "ag = performDSSP('6q21')\n",
    "os.remove('6q21.pdb')\n",
    "os.remove('6q21.dssp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SASAs = np.zeros(190)\n",
    "SSTRs = np.zeros(190)\n",
    "SASAs[:] = np.nan\n",
    "SSTRs[:] = np.nan\n",
    "\n",
    "ag_ca = ag['A'].ca\n",
    "for resid, sasa, sstr in zip(ag_ca.getResnums(), ag_ca.getData('dssp_acc'), ag_ca.getSecstrs()):\n",
    "    SASAs[resid-1] = sasa\n",
    "    if sstr in list('GHI'): # helix\n",
    "        _sstr = 2\n",
    "    elif sstr in list('EB'): # strand\n",
    "        _sstr = 1\n",
    "    else: # loop\n",
    "        _sstr = np.nan\n",
    "    SSTRs[resid-1] = _sstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (res_i, res_f) in enumerate([(1,95), (95,190)]):\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(12, 0.5))\n",
    "    for ax in (ax0, ax1):\n",
    "        ax.tick_params(axis='both', which='both', left=False, bottom=False, labelbottom=False, labelleft=False)\n",
    "    # plot secondary structure\n",
    "    SSTR_plot = SSTRs[res_i-1:res_f].reshape((1,-1))\n",
    "    ax0.imshow(SSTR_plot, aspect='auto', cmap='Paired', vmax=12)\n",
    "    # plot SASA\n",
    "    SASA_plot = SASAs[res_i-1:res_f].reshape((1,-1))\n",
    "    ax1.imshow(SASA_plot, aspect='auto', cmap='YlGn')\n",
    "    fig.savefig(f'figures/sat_mutagen-active-{i+1}-strip', dip=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agreement with experimental measurements shown on PDB structure\n",
    "We highlight on the 3D structure of RAS those residues were Rhapsody generally fails to provide correct predictions, in an attempt to identify the method's limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = np.logical_and(~np.isnan(exp_scores['regulated_RAS']), ~np.isnan(exp_scores['regulated_RAS']))\n",
    "exp_score = exp_scores['regulated_RAS']\n",
    "comput_score = rh_2.predictions['score']\n",
    "\n",
    "exp_cutoff    = np.nanmedian(exp_score)\n",
    "comput_cutoff = rh_2.CVsummary['optimal cutoff'][0]\n",
    "\n",
    "FPs = np.logical_and(exp_score > exp_cutoff, comput_score > comput_cutoff)\n",
    "FNs = np.logical_and(exp_score < exp_cutoff, comput_score < comput_cutoff)\n",
    "\n",
    "# We arbitrarily select two subsets with the least accurate predictions\n",
    "worst_FPs = np.logical_and(exp_score > 0, comput_score > 0.85)\n",
    "worst_FNs = np.logical_and(exp_score < -.4, comput_score < 0.6)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ax.plot(exp_score, comput_score, '.')\n",
    "ax.plot(exp_score[worst_FPs], comput_score[worst_FPs], 'g.', ms=8, label='FPs')\n",
    "ax.plot(exp_score[worst_FNs], comput_score[worst_FNs], 'r.', ms=8, label='FNs')\n",
    "\n",
    "ax.axvline(exp_cutoff, ls='--', c='k')\n",
    "ax.axhline(comput_cutoff, ls='--', c='k')\n",
    "\n",
    "ax.set_ylabel('Rhapsody score')\n",
    "ax.set_xlabel('exp. ΔE')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'figures/scatter_plot-FPsFNs.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_FP_resids = set([int(s.split()[2]) for s in rh_2.Uniprot2PDBmap['PDB SAV coords'][worst_FPs]])\n",
    "worst_FN_resids = set([int(s.split()[2]) for s in rh_2.Uniprot2PDBmap['PDB SAV coords'][worst_FNs]])\n",
    "# the two sets are mutually exclusive\n",
    "worst_FP_resids.intersection(worst_FN_resids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = parsePDB('6q21', chain='A').select('protein and resid 2 to 166')\n",
    "\n",
    "# replace the B-factor column in chain A with Rhapsody predictions\n",
    "PDBresids = pdb.getResnums()\n",
    "new_betas = np.zeros_like(PDBresids, dtype=float)\n",
    "for i, resid in enumerate(PDBresids):\n",
    "    if resid in worst_FP_resids:\n",
    "        beta = 1\n",
    "    elif resid in worst_FN_resids:\n",
    "        beta = -1\n",
    "    else:\n",
    "        beta = 0\n",
    "    new_betas[i] = beta\n",
    "# write modified PDB\n",
    "pdb.setBetas(new_betas)\n",
    "f = writePDB(f'figures/mapped_pdb-FPsFNs', pdb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
